{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth_mapping.ipynb\n",
    "\n",
    "# Python notebook for prototyping implementation of 3D depth mapping algorithm from the following paper:\n",
    "# J. Wlodek, K. J. Gofron, Y. Q. Cai; Achieving 3D imaging through focus stacking.\n",
    "# AIP Conf. Proc. 15 January 2019; 2054 (1): 050001. https://doi.org/10.1063/1.5084619\n",
    "\n",
    "# Bennett Wu - 11/17/2023\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_array(arr: np.array, uint8_mode=False) -> np.array:\n",
    "    '''\n",
    "    Normalizes numpy array to be float32 with range 0-1 or uint8 with range 0-255\n",
    "\n",
    "    arr - array to normalize\n",
    "    uint8_mode - select float32 or uint8, defaults to float32\n",
    "\n",
    "    returns - uint8 or float32 numpy array in same shape as input\n",
    "    '''\n",
    "    arr = arr.astype('float32')\n",
    "    arr = (arr - np.min(arr)) / (np.max(arr) - np.min(arr))\n",
    "    if uint8_mode:\n",
    "        arr *= 255\n",
    "        arr = arr.astype('uint8')\n",
    "    return arr\n",
    "\n",
    "\n",
    "def load_image(path: os.PathLike) -> np.array:\n",
    "    '''\n",
    "    Loads a given image in RGB from given path\n",
    "\n",
    "    path - path to image\n",
    "\n",
    "    returns - float32 numpy array representing an RGB image\n",
    "    '''\n",
    "    try:\n",
    "        bgr_img = cv2.imread(path)\n",
    "        rgb_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)\n",
    "        return normalize_array(rgb_img)\n",
    "    except:\n",
    "        raise Exception(f'Failed to load image: {path}')\n",
    "\n",
    "\n",
    "def rgb_to_gray(im: np.array) -> np.array:\n",
    "    '''\n",
    "    Converts a RGB image to grayscale\n",
    "\n",
    "    im - image to convert\n",
    "\n",
    "    returns - numpy array representing a grayscale image\n",
    "    '''\n",
    "    assert len(im.shape) == 3  # Image must be RGB\n",
    "    return cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "def plt_img(ax: plt.axis, img: np.array, title='') -> None:\n",
    "    '''\n",
    "    Plots given image onto matplot axis with an optional title\n",
    "\n",
    "    ax - matplot plot axis (can just pass in matplot.pyplot, or a subplot axis)\n",
    "    img - grayscale or RGB image to plot\n",
    "    title - optional plot title\n",
    "    '''\n",
    "    cmap = 'gray'\n",
    "    if (len(img.shape) == 3 and img.shape[2] == 3):\n",
    "        cmap = None\n",
    "    ax.imshow(img, cmap=cmap)\n",
    "    ax.axis('off')\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "\n",
    "def save_img(path: os.PathLike, img: np.array) -> None:\n",
    "    '''\n",
    "    Saves given image to given path. Converts non uint8 images to uint8\n",
    "\n",
    "    path - path to save image to\n",
    "    img - image to save\n",
    "    '''\n",
    "    if (len(img.shape) == 3):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    if (img.dtype != 'uint8'):\n",
    "        img = normalize_array(img, uint8_mode=True)\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    path = os.path.abspath(path)\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cv2.imwrite(path, img)\n",
    "    print(f\"Image saved at {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images to stack and input focal depths\n",
    "img_dir = './test_images/'\n",
    "img_names = [\n",
    "    'hf001.jpg', 'hf005.jpg', 'hf010.jpg', 'hf015.jpg',\n",
    "    'hf020.jpg', 'hf025.jpg', 'hf030.jpg', 'hf035.jpg',\n",
    "]\n",
    "\n",
    "focal_depths = np.array([\n",
    "    1, 5, 10, 15, 20, 25, 30, 35\n",
    "])\n",
    "\n",
    "images = np.array([\n",
    "    load_image(os.path.join(img_dir, name)) for name in img_names\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an image for testing\n",
    "test_img = images[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_convolve(im: np.array, ksize: int) -> np.array:\n",
    "    '''\n",
    "    Convolves given image using a gaussian kernel\n",
    "\n",
    "    im - image to blur\n",
    "    ksize - Size in pixels of gaussian kernel. Must be odd.\n",
    "\n",
    "    returns - numpy array of convolved image\n",
    "    '''\n",
    "    # ksize must be odd\n",
    "    assert ksize % 2 == 1\n",
    "    # Grayscale or RGB images allowed\n",
    "    assert len(img.shape) == 2 or len(img.shape) == 3\n",
    "\n",
    "    return cv2.GaussianBlur(im, (ksize, ksize), 0)\n",
    "\n",
    "\n",
    "def laplacian_convolve(im: np.array, ksize: int) -> np.array:\n",
    "    '''\n",
    "    Convolves given image using a laplacian kernel\n",
    "\n",
    "    im - image to convolve\n",
    "    ksize - Size in pixels of laplacian kernel. Must be odd.\n",
    "\n",
    "    returns - numpy array of convolved image\n",
    "    '''\n",
    "    # ksize must be odd\n",
    "    assert ksize % 2 == 1\n",
    "    # Grayscale or RGB images allowed\n",
    "    assert len(img.shape) == 2 or len(img.shape) == 3\n",
    "    return cv2.Laplacian(im, ddepth=cv2.CV_32F, ksize=ksize)\n",
    "\n",
    "\n",
    "# Test functions with image\n",
    "img = rgb_to_gray(test_img)\n",
    "blur = gauss_convolve(img, 25)\n",
    "sharp = laplacian_convolve(blur, 25)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 20))\n",
    "plt_img(ax[0], img)\n",
    "plt_img(ax[1], blur)\n",
    "plt_img(ax[2], sharp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function adapted from https://github.com/bznick98/Focus_Stacking @ d61993a\n",
    "\n",
    "# # Note - This is not working well, a different approach may be needed\n",
    "\n",
    "# def align_images(images: list[np.array], max_features=1000, good_match_thresh=0.75):\n",
    "#     # use uint8 images for cv2.drawMatches()\n",
    "#     images = [normalize_array(img, uint8_mode=True) for img in images]\n",
    "\n",
    "#     ref = images[0]\n",
    "#     aligned_images = [ref]\n",
    "\n",
    "#     # find homography between other images and ref img\n",
    "#     match_images = []\n",
    "#     for img in images[1:]:\n",
    "#         height, width = img.shape\n",
    "\n",
    "#         detector = cv2.KAZE_create(max_features)\n",
    "\n",
    "#         # find keypoints and descriptors\n",
    "#         kp_a, des_a = detector.detectAndCompute(img, None)\n",
    "#         kp_b, des_b = detector.detectAndCompute(ref, None)\n",
    "\n",
    "#         # Matcher\n",
    "#         bf = cv2.BFMatcher()\n",
    "#         matches = bf.knnMatch(des_a, des_b, k=2)\n",
    "\n",
    "#         # Apply ratio test\n",
    "#         good = []\n",
    "#         for m, n in matches:\n",
    "#             if m.distance < good_match_thresh*n.distance:\n",
    "#                 good.append(m)\n",
    "#         numMatches = int(len(good))\n",
    "#         matches = good\n",
    "\n",
    "#         match_images.append(\n",
    "#             cv2.drawMatches(ref, kp_a, img, kp_b, matches, None)\n",
    "#         )\n",
    "\n",
    "#         # extract location of good matches\n",
    "#         pts_a = np.zeros((numMatches, 2), dtype=np.float32)\n",
    "#         pts_b = np.zeros((numMatches, 2), dtype=np.float32)\n",
    "\n",
    "#         for idx, match in enumerate(matches):\n",
    "#             pts_a[idx, :] = kp_a[match.queryIdx].pt\n",
    "#             pts_b[idx, :] = kp_b[match.trainIdx].pt\n",
    "\n",
    "#         H, _ = cv2.findHomography(pts_a, pts_b, cv2.RANSAC)\n",
    "\n",
    "#         img_warped = cv2.warpPerspective(img, H, (width, height))\n",
    "#         aligned_images.append(img_warped)\n",
    "\n",
    "#     return aligned_images, match_images\n",
    "\n",
    "# grayscale_img = [rgb_to_gray(img) for img in images]\n",
    "# aligned_images, match_images = align_images(grayscale_img)\n",
    "\n",
    "# plt_img(plt, match_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_image(img: np.array, template_win_size=7, search_win_size=21, filter_strength=10) -> np.array:\n",
    "    '''\n",
    "    Denoises a given image\n",
    "\n",
    "    img - image to denoise\n",
    "    template_win_size - Size in pixels of the template patch that is used to compute weights. Should be odd. Recommended value 7 pixels \n",
    "    search_win_size - Size in pixels of the window that is used to compute weighted average for given pixel. Should be odd. \n",
    "                      Affect performance linearly: greater searchWindowsSize - greater denoising time. Recommended value 21 pixels \n",
    "    filter_strength - Denoising strength. Higher value removes more noise but removes details.\n",
    "\n",
    "    returns - numpy array representing denoised image\n",
    "    '''\n",
    "    # Window sizes must be odd\n",
    "    assert template_win_size % 2 == 1\n",
    "    # Window sizes must be odd\n",
    "    assert search_win_size % 2 == 1\n",
    "    # Grayscale or RGB images allowed\n",
    "    assert len(img.shape) == 2 or len(img.shape) == 3\n",
    "\n",
    "    img = normalize_array(img, uint8_mode=True)\n",
    "    img = cv2.fastNlMeansDenoising(\n",
    "        img, None, template_win_size, search_win_size, filter_strength\n",
    "    )\n",
    "    return normalize_array(img)\n",
    "\n",
    "\n",
    "img = images[1]\n",
    "gray = normalize_array(rgb_to_gray(img), uint8_mode=True)\n",
    "denoised = denoise_image(gray, 7, 21, 3)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
    "plt_img(ax[0], gray)\n",
    "plt_img(ax[1], denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_image(img: np.array, kernel_size=7) -> np.array:\n",
    "    '''\n",
    "    Smoothes given image with a median blur\n",
    "\n",
    "    img - numpy array of RGB or grayscale image\n",
    "    kernel_size - Size in pixels of median blur kernel\n",
    "\n",
    "    returns - numpy array representing smoothed image\n",
    "    '''\n",
    "    # Kernel size must be odd\n",
    "    assert kernel_size % 2 == 1\n",
    "    # Grayscale or RGB images allowed\n",
    "    assert len(img.shape) == 2 or len(img.shape) == 3\n",
    "\n",
    "    img = cv2.medianBlur(img, kernel_size)\n",
    "    return img\n",
    "\n",
    "\n",
    "img = images[1]\n",
    "smoothed = smooth_image(normalize_array(img, uint8_mode=True), 15)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
    "plt_img(ax[0], img)\n",
    "plt_img(ax[1], smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthMapArgs:\n",
    "    # Arguments for alignment of input images\n",
    "    # max_align_features = 1000\n",
    "    # good_feature_thresh = 0.85\n",
    "\n",
    "    # Arguments for denoising input images\n",
    "    denoise_temp_win_size = 7\n",
    "    denoise_search_win_size = 21\n",
    "    denoise_strength = 3\n",
    "\n",
    "    # Arguments for calculating sharpness values\n",
    "    gaussian_kernel_size = 3\n",
    "    laplacian_kernel_size = 3\n",
    "\n",
    "    # Arguments for smoothing depth map\n",
    "    merge_tile_size = 3\n",
    "    smooth_kernel_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpness_vals(image: np.array, args: DepthMapArgs) -> np.array:\n",
    "    '''\n",
    "    Calculates sharpness rankings of given image using Laplacian of Gaussian kernel\n",
    "    Converts image to grayscale, denoises image, and then runs a LoG kernel over image\n",
    "\n",
    "    image - numpy array of RGB image to calculate sharpness values of\n",
    "    args - tuneable arguments for depth mapping algorithm. See DepthMapArgs class\n",
    "\n",
    "    returns - 2d numpy array of sharpness rankings, higher = sharper\n",
    "    '''\n",
    "    assert args.gaussian_kernel_size % 2 == 1  # ksize must be odd\n",
    "    assert args.laplacian_kernel_size % 2 == 1  # ksize must be odd\n",
    "\n",
    "    temp_win = args.denoise_temp_win_size\n",
    "    search_win = args.denoise_search_win_size\n",
    "    denoise_strength = args.denoise_strength\n",
    "\n",
    "    gray = rgb_to_gray(image)\n",
    "    denoise = denoise_image(gray, temp_win, search_win, denoise_strength)\n",
    "    blur = gauss_convolve(denoise, args.gaussian_kernel_size)\n",
    "    sharp = laplacian_convolve(blur, args.laplacian_kernel_size)\n",
    "\n",
    "    return sharp\n",
    "\n",
    "\n",
    "def depth_mapping(images: np.array, focal_depths: np.array, args: DepthMapArgs) -> tuple[np.array, np.array]:\n",
    "    '''\n",
    "    Computes depth map and focus stacked image from given images and focal_depths\n",
    "\n",
    "    images - array of grayscale or RGB images\n",
    "    focal_depths - numpy array of focal depths (indexwise match with images)\n",
    "    args - tuneable arguments for depth mapping algorithm. See DepthMapArgs class\n",
    "\n",
    "    returns - tuple of depth map (2D uint8 numpy array) and focus stacked image (numpy array simplar to images[0])\n",
    "    '''\n",
    "    assert len(images.shape) == 4  # Expect list of RGB images\n",
    "\n",
    "    # Focal depths should be unique and sorted\n",
    "    assert np.sum(np.unique(focal_depths) != focal_depths) == 0\n",
    "\n",
    "    # Align images with on another\n",
    "    # images, _ = align_images(\n",
    "    #     images,\n",
    "    #     args.max_align_features,\n",
    "    #     args.good_feature_thresh\n",
    "    # )\n",
    "\n",
    "    # Normalize depths according to paper: I * (f_max - f_min) / N\n",
    "    norm = (np.max(focal_depths) - np.min(focal_depths)) / len(focal_depths)\n",
    "    focal_depths = focal_depths * norm\n",
    "\n",
    "    # Calculate sharpness ranking of images\n",
    "    sharpness_ranking = np.array([sharpness_vals(img, args) for img in images])\n",
    "\n",
    "    # Use image index as proxy for depth for now\n",
    "    _, height, width = sharpness_ranking.shape\n",
    "    depth_index = np.zeros((height, width), dtype='uint8')\n",
    "\n",
    "    tile_size = args.merge_tile_size\n",
    "    for tile_r in range(0, height - tile_size + 1, tile_size):\n",
    "        for tile_c in range(0, width - tile_size + 1, tile_size):\n",
    "            tile_sharp = sharpness_ranking[\n",
    "                :,\n",
    "                tile_r: tile_r+tile_size,\n",
    "                tile_c: tile_c+tile_size\n",
    "            ]\n",
    "\n",
    "            # For each tile, find the maximum sharpness in that tile\n",
    "            # Set depth of entire tile to that maximum sharpness\n",
    "            max_sharp_index = 0\n",
    "            max_sharp_val = np.max(tile_sharp[0])\n",
    "            for i in range(1, tile_sharp.shape[0]):\n",
    "                if np.max(tile_sharp[i]) > max_sharp_val:\n",
    "                    max_sharp_index = i\n",
    "                    max_sharp_val = np.max(tile_sharp[i])\n",
    "\n",
    "            for r in range(tile_r, tile_r + tile_size):\n",
    "                for c in range(tile_c, tile_c + tile_size):\n",
    "                    depth_index[r, c] = max_sharp_index\n",
    "\n",
    "    # Smooth out depths with a median blur\n",
    "    depth_index = smooth_image(depth_index, args.smooth_kernel_size)\n",
    "\n",
    "    # Calculate masks and generate stacked image\n",
    "    stacked = np.zeros_like(images[0])\n",
    "    for i in range(len(focal_depths)):\n",
    "        mask = depth_index == i\n",
    "        stacked += np.repeat(mask[..., None],\n",
    "                             images.shape[3], axis=2) * images[i]\n",
    "\n",
    "    # Scale so that 0 is the furthest point, 255 is the closest\n",
    "    depth_map = focal_depths[depth_index]\n",
    "    depth_map = 255 - normalize_array(depth_map, uint8_mode=True)\n",
    "\n",
    "    return depth_map, stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = DepthMapArgs()\n",
    "\n",
    "depth, stack = depth_mapping(images, focal_depths, args)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
    "plt_img(ax[0], stack)\n",
    "plt_img(ax[1], depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_in(img: np.array, amount: tuple[int, int]) -> np.array:\n",
    "  '''\n",
    "  Crops a given image in horizontal or vertical direction\n",
    "\n",
    "  img - numpy array of image to crop\n",
    "  amount - tuple of vertical crop and horizontal crop amount\n",
    "\n",
    "  returns - numpy array represtning cropped image\n",
    "  '''\n",
    "  return img[amount[0]:-amount[0], amount[1]:-amount[1]]\n",
    "\n",
    "crop = (15, 25)\n",
    "stack_crop = crop_in(stack, crop)\n",
    "depth_crop = crop_in(depth, crop)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
    "plt_img(ax[0], stack_crop)\n",
    "plt_img(ax[1], depth_crop)\n",
    "\n",
    "save_img('./outputs/stack.png', stack_crop)\n",
    "save_img('./outputs/depth.png', depth_crop)\n",
    "\n",
    "# Visualize on https://depthplayer.ugocapeto.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
