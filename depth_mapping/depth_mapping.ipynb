{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth_mapping.ipynb\n",
    "\n",
    "# Python notebook for prototyping implementation for 3D depth mapping algorithm from the following paper:\n",
    "# J. Wlodek, K. J. Gofron, Y. Q. Cai; Achieving 3D imaging through focus stacking.\n",
    "# AIP Conf. Proc. 15 January 2019; 2054 (1): 050001. https://doi.org/10.1063/1.5084619\n",
    "\n",
    "# Bennett Wu - 11/17/2023\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_array(img: np.array, uint8_mode=False) -> np.array:\n",
    "    img = img.astype('float32')\n",
    "    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "    if uint8_mode:\n",
    "        img *= 255\n",
    "        img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_image(path: os.PathLike) -> np.array:\n",
    "    try:\n",
    "        bgr_img = cv2.imread(path)\n",
    "        rgb_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)\n",
    "        return normalize_array(rgb_img)\n",
    "    except:\n",
    "        raise Exception(f'Failed to load image: {path}')\n",
    "\n",
    "\n",
    "\n",
    "def rgb_to_gray(im: np.array) -> np.array:\n",
    "    return cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "\n",
    "def plt_img(ax: plt.axis, img: np.array, title='') -> None:\n",
    "    cmap = 'gray'\n",
    "    if (len(img.shape) == 3 and img.shape[2] == 3):\n",
    "        cmap = None\n",
    "    ax.imshow(img, cmap=cmap)\n",
    "    ax.axis('off')\n",
    "    if title:\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './test_images/'\n",
    "img_names = [\n",
    "    'hf001.jpg', 'hf005.jpg', 'hf010.jpg', 'hf015.jpg',\n",
    "    'hf020.jpg', 'hf025.jpg', 'hf030.jpg', 'hf035.jpg',\n",
    "    # '1.jpg', '2.jpg'\n",
    "]\n",
    "\n",
    "focal_depths = [\n",
    "    1, 5, 10, 15, 20, 25, 30, 35\n",
    "    # 1, 2\n",
    "]\n",
    "\n",
    "focal_depths = np.array(focal_depths)\n",
    "images = np.array([load_image(os.path.join(img_dir, name))\n",
    "                  for name in img_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(sigma: float, kernel_half_size: int) -> np.array:\n",
    "    window_size = kernel_half_size*2+1\n",
    "    gaussian_kernel_1d = sp.signal.windows.gaussian(\n",
    "        window_size, std=sigma).reshape(window_size, 1)\n",
    "    gaussian_kernel_2d = np.outer(gaussian_kernel_1d, gaussian_kernel_1d)\n",
    "    gaussian_kernel_2d /= np.sum(gaussian_kernel_2d)\n",
    "\n",
    "    return gaussian_kernel_2d\n",
    "\n",
    "\n",
    "def gauss_convolve(im: np.array, ksize: int) -> np.array:\n",
    "    assert ksize % 2 == 1  # ksize must be odd\n",
    "    assert len(img.shape) == 2 or len(img.shape) == 3 # Grayscale or RGB images allowed\n",
    "    return cv2.GaussianBlur(im, (ksize, ksize), 0)\n",
    "\n",
    "\n",
    "def laplacian_convolve(im: np.array, ksize: int) -> np.array:\n",
    "    assert ksize % 2 == 1  # ksize must be odd\n",
    "    assert len(img.shape) == 2 or len(img.shape) == 3 # Grayscale or RGB images allowed\n",
    "    return cv2.Laplacian(im, ddepth=cv2.CV_32F, ksize=ksize)\n",
    "\n",
    "img = rgb_to_gray(images[3])\n",
    "blur = gauss_convolve(img, 25)\n",
    "sharp = laplacian_convolve(blur, 25)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 20))\n",
    "plt_img(ax[0], img)\n",
    "plt_img(ax[1], blur)\n",
    "plt_img(ax[2], sharp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function adapted from https://github.com/bznick98/Focus_Stacking @ d61993a\n",
    "\n",
    "# Note - This is not working well, a different approach may be needed\n",
    "\n",
    "def align_images(images: list[np.array], max_features=1000, good_match_thresh=0.75):\n",
    "    # use uint8 images for cv2.drawMatches()\n",
    "    images = [normalize_array(img, uint8_mode=True) for img in images]\n",
    "\n",
    "    ref = images[0]\n",
    "    aligned_images = [ref]\n",
    "\n",
    "    # find homography between other images and ref img\n",
    "    match_images = []\n",
    "    for img in images[1:]:\n",
    "        height, width = img.shape\n",
    "\n",
    "        detector = cv2.KAZE_create(max_features)\n",
    "\n",
    "        # find keypoints and descriptors\n",
    "        kp_a, des_a = detector.detectAndCompute(img, None)\n",
    "        kp_b, des_b = detector.detectAndCompute(ref, None)\n",
    "\n",
    "        # Matcher\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(des_a, des_b, k=2)\n",
    "\n",
    "        # Apply ratio test\n",
    "        good = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < good_match_thresh*n.distance:\n",
    "                good.append(m)\n",
    "        numMatches = int(len(good))\n",
    "        matches = good\n",
    "\n",
    "        match_images.append(\n",
    "            cv2.drawMatches(ref, kp_a, img, kp_b, matches, None)\n",
    "        )\n",
    "\n",
    "        # extract location of good matches\n",
    "        pts_a = np.zeros((numMatches, 2), dtype=np.float32)\n",
    "        pts_b = np.zeros((numMatches, 2), dtype=np.float32)\n",
    "\n",
    "        for idx, match in enumerate(matches):\n",
    "            pts_a[idx, :] = kp_a[match.queryIdx].pt\n",
    "            pts_b[idx, :] = kp_b[match.trainIdx].pt\n",
    "\n",
    "        H, _ = cv2.findHomography(pts_a, pts_b, cv2.RANSAC)\n",
    "\n",
    "        img_warped = cv2.warpPerspective(img, H, (width, height))\n",
    "        aligned_images.append(img_warped)\n",
    "\n",
    "    return aligned_images, match_images\n",
    "\n",
    "grayscale_img = [rgb_to_gray(img) for img in images]\n",
    "aligned_images, match_images = align_images(grayscale_img)\n",
    "\n",
    "plt_img(plt, match_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_image(img: np.array, template_win_size=7, search_win_size=21, filter_strength=10) -> np.array:\n",
    "    assert template_win_size % 2 == 1  # Window sizes must be odd\n",
    "    assert search_win_size % 2 == 1    # Window sizes must be odd\n",
    "    assert len(img.shape) == 2 or len(img.shape) == 3 # Grayscale or RGB images allowed\n",
    "    \n",
    "    img = normalize_array(img, uint8_mode=True)\n",
    "    img = cv2.fastNlMeansDenoising(img, None, template_win_size, search_win_size, filter_strength)\n",
    "    return normalize_array(img)\n",
    "\n",
    "\n",
    "img = images[3]\n",
    "gray = normalize_array(rgb_to_gray(img), uint8_mode=True)\n",
    "denoised = denoise_image(gray, 7, 21, 3)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
    "plt_img(ax[0], gray)\n",
    "plt_img(ax[1], denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_image(img: np.array, kernel_size=7) -> np.array:\n",
    "  assert kernel_size % 2 == 1 # Kernel size must be odd\n",
    "  assert len(img.shape) == 2 or len(img.shape) == 3 # Grayscale or RGB images allowed\n",
    "\n",
    "  img = normalize_array(img, uint8_mode=True)\n",
    "  img = cv2.medianBlur(img, kernel_size)\n",
    "  return img\n",
    "\n",
    "img = images[3]\n",
    "smoothed = smooth_image(img, 15)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
    "plt_img(ax[0], img)\n",
    "plt_img(ax[1], smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthMapArgs:\n",
    "    def __init__(self):\n",
    "        self\n",
    "    gaussian_kernel_size: int\n",
    "    laplacian_kernel_size: int\n",
    "    merge_tile_size: int\n",
    "    # max_align_features: int\n",
    "    # good_feature_thresh: float\n",
    "    denoise_temp_win_size: int\n",
    "    denoise_search_win_size: int\n",
    "    denoise_strength: int\n",
    "    smooth_kernel_size: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpness_vals(grayscale_img: np.array, args: DepthMapArgs) -> np.array:\n",
    "    assert args.gaussian_kernel_size % 2 == 1  # ksize must be odd\n",
    "    assert args.laplacian_kernel_size % 2 == 1  # ksize must be odd\n",
    "\n",
    "    sharp_values = []\n",
    "    for image in grayscale_img:\n",
    "        denoise = denoise_image(image, args.denoise_temp_win_size,\n",
    "                                args.denoise_search_win_size, args.denoise_strength)\n",
    "        blur = gauss_convolve(denoise, args.gaussian_kernel_size)\n",
    "        sharp = laplacian_convolve(blur, args.laplacian_kernel_size)\n",
    "        sharp_values.append(sharp)\n",
    "\n",
    "    return np.array(sharp_values)\n",
    "\n",
    "\n",
    "def depth_mapping(images: np.array, focal_depths: np.array, args: DepthMapArgs):\n",
    "    # images, _ = align_images(\n",
    "    #     images,\n",
    "    #     args.max_align_features,\n",
    "    #     args.good_feature_thresh\n",
    "    # )\n",
    "    assert len(np.unique(focal_depths)) ==  len(focal_depths) # Focal depths should be unique\n",
    "\n",
    "    norm_depth = normalize_array(focal_depths, uint8_mode=True)\n",
    "\n",
    "    grayscale_imgs = [rgb_to_gray(img) for img in images]\n",
    "    sharp_values = sharpness_vals(grayscale_imgs, args)\n",
    "    max_sharp = np.argmax(sharp_values, axis=0)\n",
    "\n",
    "    tile_size = args.merge_tile_size\n",
    "    num_img, height, width = sharp_values.shape\n",
    "    stacked = np.zeros((height, width, 3))\n",
    "    depth_map = np.zeros((height, width))\n",
    "\n",
    "    for tile_r in range(0, height - tile_size, tile_size):\n",
    "        for tile_c in range(0, width - tile_size, tile_size):\n",
    "            tile_sharp = sharp_values[\n",
    "                :,\n",
    "                tile_r: tile_r+tile_size,\n",
    "                tile_c: tile_c+tile_size\n",
    "            ]\n",
    "\n",
    "            arg_max = 0\n",
    "            max_sharp = np.max(tile_sharp[0])\n",
    "            for i in range(1, tile_sharp.shape[0]):\n",
    "                if np.max(tile_sharp[i]) > max_sharp:\n",
    "                    arg_max = i\n",
    "                    max_sharp = np.max(tile_sharp[i])\n",
    "            for r in range(tile_r, tile_r + tile_size):\n",
    "                for c in range(tile_c, tile_c + tile_size):\n",
    "                    depth_map[r, c] = norm_depth[arg_max]\n",
    "    \n",
    "    depth_map = smooth_image(depth_map, args.smooth_kernel_size)\n",
    "    masks = []\n",
    "    for depth in norm_depth:\n",
    "        masks.append(depth_map == depth)\n",
    "\n",
    "    for i in range(len(masks)):\n",
    "        for j in range(3):\n",
    "            stacked[:, :, j] += masks[i] * images[i, :, :, j]\n",
    "\n",
    "    return depth_map, stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = DepthMapArgs()\n",
    "args.gaussian_kernel_size = 3\n",
    "args.laplacian_kernel_size = 3\n",
    "args.merge_tile_size = 3\n",
    "# args.max_align_features = 10000\n",
    "# args.good_feature_thresh = 0.85\n",
    "args.denoise_temp_win_size = 7\n",
    "args.denoise_search_win_size = 21\n",
    "args.denoise_strength = 3\n",
    "args.smooth_kernel_size = 25\n",
    "\n",
    "depth, stack = depth_mapping(images, focal_depths, args)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
    "plt_img(ax[0], stack)\n",
    "plt_img(ax[1], depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
